{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d01a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f67f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "OO = pd.read_parquet('data/REP_ORD_ORDER.parquet',engine = 'pyarrow',columns = ['ORDER_ID','ORDER_NUM','JOB_CODE','ELIGIBLE'])\n",
    "JC = pd.read_parquet('data/REP_ORD_JOB_CODE.parquet',engine = 'pyarrow',columns = ['JOB_CODE_ID','NAME','CORE_DESCRIPTION'])\n",
    "OOS = pd.read_parquet('data/REP_ORD_ORDER_STATE.parquet',engine = 'pyarrow',columns=['ORDER_STATE_ID','FOR_ORDER','ORDER_NUM','LATEST_ASSIGNMENT','TOTAL_TIME_EN_ROUTE','TOTAL_TIME_ON_SITE','ONSITE_AT', 'COMPLETED', 'ENROUTE_AT'])\n",
    "AA = pd.read_parquet('data/REP_ASN_ASSIGNMENT.parquet',engine = 'pyarrow',columns = ['ASSIGNMENT_ID','FOR_RESOURCE'])\n",
    "LR = pd.read_parquet('data/REP_LAB_RESOURCE.parquet',engine = 'pyarrow',columns = ['RESOURCE_ID','FOR_USER'])\n",
    "LU = pd.read_parquet('data/REP_LAB_USER.parquet',engine = 'pyarrow',columns = ['USER_ID','LOGON_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ac1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = OO.merge(JC,left_on = 'JOB_CODE',right_on='JOB_CODE_ID')\n",
    "DF = DF.merge(OOS, left_on = 'ORDER_ID', right_on = 'FOR_ORDER')\n",
    "DF = DF.merge(AA,left_on = 'LATEST_ASSIGNMENT',right_on = 'ASSIGNMENT_ID')\n",
    "DF = DF.merge(LR,left_on = 'FOR_RESOURCE',right_on = 'RESOURCE_ID')\n",
    "DF = DF.merge(LU,left_on = 'FOR_USER',right_on = 'USER_ID')\n",
    "\n",
    "DF[:3].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_cols = ['ELIGIBLE','ONSITE_AT','COMPLETED','ENROUTE_AT',]\n",
    "\n",
    "DF[timestamp_cols] = DF[timestamp_cols].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['WORK_START'] = DF['ENROUTE_AT']  \n",
    "DF['WORK_END'] = DF['COMPLETED']    \n",
    "DF['ONSITE_START'] = DF['ONSITE_AT'] \n",
    "\n",
    "DF['ACTUAL_WORK_DURATION'] = (DF['WORK_END'] - DF['WORK_START']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_work_dates(start_time, end_time):\n",
    "    if pd.isna(start_time) or pd.isna(end_time):\n",
    "        return []\n",
    "    start_date = start_time.date()\n",
    "    end_date = end_time.date()\n",
    "    dates = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date)\n",
    "        current_date += pd.Timedelta(days=1)\n",
    "    return dates\n",
    "\n",
    "\n",
    "expanded_records = []\n",
    "\n",
    "for idx, row in DF.iterrows():\n",
    "    if pd.notna(row['WORK_START']) and pd.notna(row['WORK_END']):\n",
    "        work_dates = get_work_dates(row['WORK_START'], row['WORK_END'])\n",
    "        if len(work_dates) == 1:\n",
    "            expanded_records.append({\n",
    "                'LOGON_ID': row['LOGON_ID'],\n",
    "                'CORE_DESCRIPTION': row['CORE_DESCRIPTION'],\n",
    "                'DATE': work_dates[0],\n",
    "                'DAILY_WORK_TIME': row['ACTUAL_WORK_DURATION'],\n",
    "                'ORDER_ID': row['ORDER_ID'],\n",
    "                'JOB_CODE': row['NAME'],\n",
    "                'WORK_START': row['WORK_START'],\n",
    "                'WORK_END': row['WORK_END']\n",
    "            })\n",
    "        else:\n",
    "            total_duration = row['ACTUAL_WORK_DURATION']\n",
    "            daily_duration = total_duration / len(work_dates)\n",
    "            \n",
    "            for work_date in work_dates:\n",
    "                expanded_records.append({\n",
    "                    'LOGON_ID': row['LOGON_ID'],\n",
    "                    'CORE_DESCRIPTION': row['CORE_DESCRIPTION'],\n",
    "                    'DATE': work_date,\n",
    "                    'DAILY_WORK_TIME': daily_duration,\n",
    "                    'ORDER_ID': row['ORDER_ID'],\n",
    "                    'JOB_CODE': row['NAME'],\n",
    "                    'WORK_START': row['WORK_START'],\n",
    "                    'WORK_END': row['WORK_END']\n",
    "                })\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df[:3].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9defff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_utilization = expanded_df.groupby(['LOGON_ID', 'DATE']).agg({\n",
    "    'DAILY_WORK_TIME': 'sum',\n",
    "    'ORDER_ID': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "daily_utilization.rename(columns={\n",
    "    'DAILY_WORK_TIME': 'TOTAL_MINUTES_WORKED',\n",
    "    'ORDER_ID': 'JOBS_COUNT'\n",
    "}, inplace=True)\n",
    "\n",
    "DAILY_WORK_MIN = 7 * 60  \n",
    "daily_utilization['UTILIZATION_RATE'] = (\n",
    "    daily_utilization['TOTAL_MINUTES_WORKED'] / DAILY_WORK_MIN\n",
    ").round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ae97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_utilization['UTILIZATION_RATE_%'] = daily_utilization['UTILIZATION_RATE'] *100\n",
    "daily_utilization['DATE'] = daily_utilization['DATE'].apply(pd.to_datetime)\n",
    "daily_utilization[:5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "util_job_counts = daily_utilization.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46248b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 3, 6, 9, 12, 15, 18, float('inf')]\n",
    "labels = ['1–3', '4–6', '7–9', '10–12', '13–15', '16–18', '19+']\n",
    "util_job_counts['JOB_COUNT_RANGE'] = pd.cut(util_job_counts['JOBS_COUNT'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "job_range_avg = (\n",
    "    util_job_counts\n",
    "    .groupby('JOB_COUNT_RANGE', observed=False)['UTILIZATION_RATE_%']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig1 = px.bar(\n",
    "    job_range_avg,\n",
    "    x='JOB_COUNT_RANGE',\n",
    "    y='UTILIZATION_RATE_%',\n",
    "    text=job_range_avg['UTILIZATION_RATE_%'].round(1).astype(str) + '%',\n",
    "    title='Average Utilization Rate by Job Counts',\n",
    "    labels={'UTILIZATION_RATE_%': 'Average Utilization Rate (%)', 'JOB_COUNT_RANGE': 'Job Count Range'}\n",
    ")\n",
    "\n",
    "fig1.update_layout(template='simple_white')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "util_day_ofweek = daily_utilization.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "util_day_ofweek['DAY_OF_WEEK'] = util_day_ofweek['DATE'].dt.day_of_week\n",
    "\n",
    "map_day = {\n",
    "    0: 'Monday',\n",
    "    1: 'Tuesday',\n",
    "    2: 'Wednesday',\n",
    "    3: 'Thursday',\n",
    "    4: 'Friday',\n",
    "    5: 'Saturday',\n",
    "    6: 'Sunday'\n",
    "}\n",
    "\n",
    "util_day_ofweek['DAY_OF_WEEK'] = util_day_ofweek['DAY_OF_WEEK'].map(map_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163967b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "util_day_ofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_week_avg = (\n",
    "    util_day_ofweek\n",
    "    .groupby('DAY_OF_WEEK', observed=False)['UTILIZATION_RATE_%']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "weekday_in_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_week_avg['DAY_OF_WEEK'] = pd.Categorical(day_week_avg['DAY_OF_WEEK'], categories=weekday_in_order, ordered=True)\n",
    "day_week_avg = day_week_avg.sort_values('DAY_OF_WEEK')\n",
    "\n",
    "fig2 = px.bar(\n",
    "    day_week_avg,\n",
    "    x='DAY_OF_WEEK',\n",
    "    y='UTILIZATION_RATE_%',\n",
    "    text=day_week_avg['UTILIZATION_RATE_%'].round(1).astype(str) + '%',\n",
    "    title='Average Utilization Rate by Days of the Week',\n",
    "    labels={'UTILIZATION_RATE_%': 'Average Utilization Rate (%)', 'DAY_OF_WEEK': 'Days of the Week'}\n",
    ")\n",
    "\n",
    "fig2.update_layout(template='simple_white')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34093684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
