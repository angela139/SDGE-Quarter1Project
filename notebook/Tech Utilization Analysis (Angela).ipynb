{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OO = pd.read_parquet('sort/REP_ORD_ORDER.parquet',engine = 'pyarrow',columns = ['ORDER_ID','ORDER_NUM','JOB_CODE','ELIGIBLE', 'DISPATCH_AREA', 'SLR_ZIP', 'SLR_CITY'])\n",
    "JC = pd.read_parquet('sort/REP_ORD_JOB_CODE.parquet',engine = 'pyarrow',columns = ['JOB_CODE_ID','NAME','CORE_DESCRIPTION'])\n",
    "OOS = pd.read_parquet('sort/REP_ORD_ORDER_STATE.parquet',engine = 'pyarrow',columns=['ORDER_STATE_ID','FOR_ORDER','ORDER_NUM','LATEST_ASSIGNMENT','TOTAL_TIME_EN_ROUTE','TOTAL_TIME_ON_SITE', 'DISPATCH_AT', 'RECEIVED_AT', 'ACKNOWLEDGED_AT', 'ENROUTE_AT',\n",
    "                  'ONSITE_AT', 'COMPLETED', 'CLOSED'])\n",
    "AA = pd.read_parquet('sort/REP_ASN_ASSIGNMENT.parquet',engine = 'pyarrow',columns = ['ASSIGNMENT_ID','FOR_RESOURCE'])\n",
    "LR = pd.read_parquet('sort/REP_LAB_RESOURCE.parquet',engine = 'pyarrow',columns = ['RESOURCE_ID','FOR_USER'])\n",
    "LU = pd.read_parquet('sort/REP_LAB_USER.parquet',engine = 'pyarrow',columns = ['USER_ID','LOGON_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e94d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = OO.merge(JC,left_on = 'JOB_CODE',right_on='JOB_CODE_ID')\n",
    "DF = DF.merge(OOS, left_on = 'ORDER_ID', right_on = 'FOR_ORDER')\n",
    "DF = DF.merge(AA,left_on = 'LATEST_ASSIGNMENT',right_on = 'ASSIGNMENT_ID')\n",
    "DF = DF.merge(LR,left_on = 'FOR_RESOURCE',right_on = 'RESOURCE_ID')\n",
    "DF = DF.merge(LU,left_on = 'FOR_USER',right_on = 'USER_ID')\n",
    "print(DF[:3].T)\n",
    "print(DF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e95c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/OpenDataDE/State-zip-code-GeoJSON/master/ca_california_zip_codes_geo.min.json\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "geojson_data = response.json()\n",
    "\n",
    "DF_clean = DF[DF['SLR_ZIP'].notna()].copy()\n",
    "DF_clean['ZIP5'] = DF_clean['SLR_ZIP'].astype(str).str[:5]\n",
    "\n",
    "DF_clean['TOTAL_TIME_EN_ROUTE'] = pd.to_numeric(DF_clean['TOTAL_TIME_EN_ROUTE'], errors='coerce')\n",
    "DF_clean['TOTAL_TIME_ON_SITE'] = pd.to_numeric(DF_clean['TOTAL_TIME_ON_SITE'], errors='coerce')\n",
    "\n",
    "DF_clean['WORK_START'] = DF_clean['ENROUTE_AT']\n",
    "DF_clean['WORK_END'] = DF_clean['COMPLETED']\n",
    "\n",
    "def get_work_dates(start_time, end_time):\n",
    "    if pd.isna(start_time) or pd.isna(end_time):\n",
    "        return []\n",
    "\n",
    "    start_date = start_time.date()\n",
    "    end_date = end_time.date()\n",
    "    dates = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date)\n",
    "        current_date += pd.Timedelta(days=1)\n",
    "    return dates\n",
    "\n",
    "expanded_records = []\n",
    "\n",
    "for idx, row in DF_clean.iterrows():\n",
    "    if pd.notna(row['WORK_START']) and pd.notna(row['WORK_END']):\n",
    "        work_dates = get_work_dates(row['WORK_START'], row['WORK_END'])\n",
    "\n",
    "        if len(work_dates) == 1:\n",
    "            expanded_records.append({\n",
    "                'LOGON_ID': row['LOGON_ID'],\n",
    "                'DATE': work_dates[0],\n",
    "                'ZIP5': row['ZIP5'],\n",
    "                'TOTAL_TIME_EN_ROUTE': row['TOTAL_TIME_EN_ROUTE'],\n",
    "                'TOTAL_TIME_ON_SITE': row['TOTAL_TIME_ON_SITE']\n",
    "            })\n",
    "        else:\n",
    "            n_days = len(work_dates)\n",
    "            en_route_per_day = row['TOTAL_TIME_EN_ROUTE'] / n_days\n",
    "            onsite_per_day = row['TOTAL_TIME_ON_SITE'] / n_days\n",
    "\n",
    "            for d in work_dates:\n",
    "                expanded_records.append({\n",
    "                    'LOGON_ID': row['LOGON_ID'],\n",
    "                    'DATE': d,\n",
    "                    'ZIP5': row['ZIP5'],\n",
    "                    'TOTAL_TIME_EN_ROUTE': en_route_per_day,\n",
    "                    'TOTAL_TIME_ON_SITE': onsite_per_day\n",
    "                })\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_records)\n",
    "expanded_df['TOTAL_WORKED'] = expanded_df['TOTAL_TIME_EN_ROUTE'] + expanded_df['TOTAL_TIME_ON_SITE']\n",
    "\n",
    "daily = expanded_df.groupby(['LOGON_ID','DATE','ZIP5'], as_index=False).agg({'TOTAL_WORKED':'sum'})\n",
    "daily['DAILY_UTIL_%'] = (daily['TOTAL_WORKED'] / (7*60*60)) * 100\n",
    "\n",
    "zip_util = daily.groupby('ZIP5', as_index=False).agg({\n",
    "    'DAILY_UTIL_%': 'mean',\n",
    "    'TOTAL_WORKED': 'sum',\n",
    "    'LOGON_ID': 'count'\n",
    "})\n",
    "\n",
    "zip_util = zip_util.rename(columns={'LOGON_ID':'TOTAL_JOBS'})\n",
    "zip_util['DAILY_UTIL_%'] = zip_util['DAILY_UTIL_%'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58feb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(\n",
    "    zip_util,\n",
    "    geojson=geojson_data,\n",
    "    locations='ZIP5',\n",
    "    featureidkey='properties.ZCTA5CE10',\n",
    "    color='DAILY_UTIL_%',               \n",
    "    hover_data=['TOTAL_WORKED', 'TOTAL_JOBS'],\n",
    "    color_continuous_scale='Plasma',\n",
    "    range_color=[0, 60],\n",
    "    title='Average Technician Utilization by Zip Code'\n",
    ")\n",
    "\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":50,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ff28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['TOTAL_TIME_EN_ROUTE'] = pd.to_numeric(DF['TOTAL_TIME_EN_ROUTE'], errors='coerce')\n",
    "DF['TOTAL_TIME_ON_SITE'] = pd.to_numeric(DF['TOTAL_TIME_ON_SITE'], errors='coerce')\n",
    "\n",
    "DF['WORK_START'] = DF['ENROUTE_AT']\n",
    "DF['WORK_END'] = DF['COMPLETED']\n",
    "DF['ONSITE_START'] = DF['ONSITE_AT']\n",
    "\n",
    "DF['ACTUAL_TIME_EN_ROUTE'] = (DF['ONSITE_START'] - DF['WORK_START']).dt.total_seconds()\n",
    "DF['ACTUAL_TIME_ON_SITE'] = (DF['WORK_END'] - DF['ONSITE_START']).dt.total_seconds()\n",
    "\n",
    "\n",
    "def get_work_dates(start_time, end_time):\n",
    "    if pd.isna(start_time) or pd.isna(end_time):\n",
    "        return []\n",
    "    start_date = start_time.date()\n",
    "    end_date = end_time.date()\n",
    "    dates = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date)\n",
    "        current_date += pd.Timedelta(days=1)\n",
    "    return dates\n",
    "\n",
    "\n",
    "expanded_records = []\n",
    "\n",
    "for idx, row in DF.iterrows():\n",
    "    if pd.notna(row['WORK_START']) and pd.notna(row['WORK_END']):\n",
    "        work_dates = get_work_dates(row['WORK_START'], row['WORK_END'])\n",
    "    if len(work_dates) == 1:\n",
    "        expanded_records.append({\n",
    "        'LOGON_ID': row['LOGON_ID'],\n",
    "        'DATE': work_dates[0],\n",
    "        'TOTAL_TIME_EN_ROUTE': row['ACTUAL_TIME_EN_ROUTE'],\n",
    "        'TOTAL_TIME_ON_SITE': row['ACTUAL_TIME_ON_SITE']\n",
    "        })\n",
    "    else:\n",
    "        n_days = len(work_dates)\n",
    "        en_route_per_day = row['ACTUAL_TIME_EN_ROUTE'] / n_days\n",
    "        onsite_per_day = row['ACTUAL_TIME_ON_SITE'] / n_days\n",
    "\n",
    "        for d in work_dates:\n",
    "            expanded_records.append({\n",
    "            'LOGON_ID': row['LOGON_ID'],\n",
    "            'DATE': d,\n",
    "            'TOTAL_TIME_EN_ROUTE': en_route_per_day,\n",
    "            'TOTAL_TIME_ON_SITE': onsite_per_day\n",
    "            })\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_records)\n",
    "\n",
    "\n",
    "daily = expanded_df.groupby(['LOGON_ID', 'DATE'], as_index=False).agg({\n",
    "'TOTAL_TIME_EN_ROUTE': 'sum',\n",
    "'TOTAL_TIME_ON_SITE': 'sum'\n",
    "})\n",
    "\n",
    "\n",
    "daily['TOTAL_WORKED'] = daily['TOTAL_TIME_EN_ROUTE'] + daily['TOTAL_TIME_ON_SITE']\n",
    "daily['DAILY_UTILIZATION_RATIO'] = daily['TOTAL_WORKED'] / (7 * 60 * 60)\n",
    "daily['DAILY_UTILIZATION_%'] = daily['DAILY_UTILIZATION_RATIO'] * 100\n",
    "\n",
    "\n",
    "tech_util = daily.groupby('LOGON_ID', as_index=False).agg({\n",
    "'DAILY_UTILIZATION_RATIO': 'mean'\n",
    "})\n",
    "tech_util['UTILIZATION_%'] = tech_util['DAILY_UTILIZATION_RATIO'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['TOTAL_TIME_EN_ROUTE'] = pd.to_numeric(DF['TOTAL_TIME_EN_ROUTE'], errors='coerce')\n",
    "DF['TOTAL_TIME_ON_SITE'] = pd.to_numeric(DF['TOTAL_TIME_ON_SITE'], errors='coerce')\n",
    "\n",
    "DF['DATE'] = pd.to_datetime(DF['ELIGIBLE']).dt.date\n",
    "\n",
    "daily = (\n",
    "    DF.groupby(['LOGON_ID', 'DATE'], as_index=False)\n",
    "      .agg({'TOTAL_TIME_EN_ROUTE': 'sum', 'TOTAL_TIME_ON_SITE': 'sum'})\n",
    ")\n",
    "\n",
    "daily['TOTAL_WORKED'] = daily['TOTAL_TIME_EN_ROUTE'] + daily['TOTAL_TIME_ON_SITE']\n",
    "\n",
    "daily['DAILY_UTILIZATION_RATIO'] = (daily['TOTAL_WORKED'] / (7 * 60 * 60))\n",
    "daily['DAILY_UTILIZATION_%'] = daily['DAILY_UTILIZATION_RATIO'] * 100\n",
    "\n",
    "tech_util = (\n",
    "    daily.groupby('LOGON_ID', as_index=False)\n",
    "         .agg({'DAILY_UTILIZATION_RATIO': 'mean'})\n",
    ")\n",
    "\n",
    "tech_util['UTILIZATION_%'] = tech_util['DAILY_UTILIZATION_RATIO'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e1c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    tech_util,\n",
    "    x='UTILIZATION_%',\n",
    "    nbins=20,\n",
    "    title='Distribution of Technician Utilization for SDGE Job Assignments',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Utilization (%)',\n",
    "    yaxis_title='Number of Technicians',\n",
    "    xaxis=dict(range=[0, 100]),\n",
    "    bargap=0.05,\n",
    "    template='plotly_white',\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    hovertemplate='Utilization: %{x:.1f}%<br>Technicians: %{y}'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    annotations=[\n",
    "        dict(\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            x=0, \n",
    "            y=-0.2,\n",
    "            showarrow=False,\n",
    "            text='*Utilization = % of shift time spent traveling to and working on jobs*',\n",
    "            font=dict(size=12, color='gray'),\n",
    "            align='left'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dispatch_area = (\n",
    "    DF.groupby(['LOGON_ID', 'DISPATCH_AREA', 'DATE'], as_index=False)\n",
    "    .agg({'TOTAL_TIME_EN_ROUTE': 'sum', 'TOTAL_TIME_ON_SITE': 'sum'})\n",
    "    )\n",
    "\n",
    "daily_dispatch_area['TOTAL_WORKED'] = daily_dispatch_area['TOTAL_TIME_EN_ROUTE'] + daily_dispatch_area['TOTAL_TIME_ON_SITE']\n",
    "daily_dispatch_area['DAILY_UTILIZATION_RATIO'] = daily_dispatch_area['TOTAL_WORKED'] / (7 * 60 * 60)\n",
    "daily_dispatch_area['DAILY_UTILIZATION_%'] = daily_dispatch_area['DAILY_UTILIZATION_RATIO'] * 100\n",
    "\n",
    "dispatch_util = (\n",
    "daily_dispatch_area.groupby('DISPATCH_AREA', as_index=False)\n",
    ".agg({'DAILY_UTILIZATION_RATIO': 'mean'})\n",
    ")\n",
    "\n",
    "dispatch_util['AVG_UTILIZATION_%'] = dispatch_util['DAILY_UTILIZATION_RATIO'] * 100\n",
    "dispatch_util = dispatch_util.sort_values(by='AVG_UTILIZATION_%', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(dispatch_util,\n",
    "x='DISPATCH_AREA',\n",
    "y='AVG_UTILIZATION_%',\n",
    "text='AVG_UTILIZATION_%',\n",
    "labels={'AVG_UTILIZATION_%':'Average Utilization (%)', 'DISPATCH_AREA':'Dispatch Area'},\n",
    "title='Average Technician Utilization by Dispatch Area',\n",
    "color='AVG_UTILIZATION_%',\n",
    "color_continuous_scale='Blues')\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')\n",
    "fig.update_layout(yaxis=dict(range=[0, 50]), xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fdf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_util = tech_util.sort_values('UTILIZATION_%', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest10 = lowest_util.head(10)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(lowest10['LOGON_ID'], lowest10['UTILIZATION_%'], color='salmon')\n",
    "plt.xlabel('Utilization (%)')\n",
    "plt.ylabel('Technician')\n",
    "plt.title('Technicians with Lowest Utilization Rates')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_counts = DF.groupby('LOGON_ID').size().reset_index(name='TOTAL_JOBS')\n",
    "\n",
    "tech_util_full = tech_util.merge(job_counts, on='LOGON_ID')\n",
    "\n",
    "top10_jobs = tech_util_full.sort_values('TOTAL_JOBS', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(top10_jobs['LOGON_ID'], top10_jobs['UTILIZATION_%'], color='skyblue')\n",
    "\n",
    "for i, (util, total_jobs) in enumerate(zip(top10_jobs['UTILIZATION_%'], top10_jobs['TOTAL_JOBS'])):\n",
    "    plt.text(util + 1, i, f'{total_jobs} jobs', va='center')\n",
    "\n",
    "plt.xlabel('Average Daily Utilization (%)')\n",
    "plt.ylabel('Technician')\n",
    "plt.title('Technicians with Most Jobs and Their Average Daily Utilization')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c49303",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_counts = DF.groupby('LOGON_ID').size().reset_index(name='TOTAL_JOBS')\n",
    "tech_util_full = tech_util.merge(job_counts, on='LOGON_ID')\n",
    "tech_util_clean = tech_util_full[tech_util_full['UTILIZATION_%'] <= 100]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(tech_util_clean['TOTAL_JOBS'], tech_util_clean['UTILIZATION_%'], alpha=0.7, color='teal')\n",
    "plt.xlabel('Total Jobs')\n",
    "plt.ylabel('Average Daily Utilization (%)')\n",
    "plt.title('Technician Utilization vs. Total Jobs')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bc180",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_cols = ['COMPLETED', 'CLOSED','DISPATCH_AT', 'RECEIVED_AT', 'ACKNOWLEDGED_AT', 'ENROUTE_AT', 'ONSITE_AT']\n",
    "for col in timestamp_cols:\n",
    "    DF[col] = pd.to_datetime(DF[col], errors='coerce')\n",
    "\n",
    "DF = DF.dropna(subset=['ACKNOWLEDGED_AT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a187104",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['time_to_receive'] = (DF['RECEIVED_AT'] - DF['DISPATCH_AT']).dt.total_seconds() / 3600\n",
    "DF['time_to_ack'] = (DF['ACKNOWLEDGED_AT'] - DF['RECEIVED_AT']).dt.total_seconds() / 3600\n",
    "DF['time_to_leave'] = (DF['ENROUTE_AT'] - DF['ACKNOWLEDGED_AT']).dt.total_seconds() / 3600\n",
    "DF['time_to_enroute'] = DF['TOTAL_TIME_EN_ROUTE'] / 3600\n",
    "DF['onsite_duration'] = DF['TOTAL_TIME_ON_SITE'] / 3600\n",
    "DF['post_completion_delay'] = (DF['CLOSED'] - DF['COMPLETED']).dt.total_seconds() / 3600\n",
    "\n",
    "delays = DF[['time_to_receive', 'time_to_ack', 'time_to_leave', 'time_to_enroute','onsite_duration','post_completion_delay']].mean().sort_values(ascending=False)\n",
    "\n",
    "delays_df = delays.reset_index()\n",
    "delays_df.columns = ['Stage', 'Average_Hours']\n",
    "\n",
    "fig = px.bar(\n",
    "    delays_df,\n",
    "    x='Average_Hours',\n",
    "    y='Stage',\n",
    "    orientation='h',\n",
    "    text='Average_Hours',\n",
    "    title=\"Average Duration Between Job Lifecycle Stages (hrs)\",\n",
    "    labels={'Average_Hours':'Hours', 'Stage':'Job Stage'}\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.2f} hrs', textposition='outside')\n",
    "fig.update_layout(yaxis={'categoryorder':'total ascending'}, margin=dict(l=150, r=50, t=50, b=150))\n",
    "\n",
    "caption_text = (\n",
    "    \"time_to_receive: Time from job dispatch to technician receiving it<br>\"\n",
    "    \"time_to_ack: Time from technician receiving job to acknowledging it <br>\"\n",
    "    \"time_to_leave: Time from technician acknowledging job to going to job site<br>\"\n",
    "    \"time_to_enroute: Time spent traveling to the job site<br>\"\n",
    "    \"onsite_duration: Time spent working at the job site<br>\"\n",
    "    \"post_completion_delay: Time from job completion to closing job\"\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    text=caption_text,\n",
    "    xref=\"paper\",\n",
    "    yref=\"paper\",\n",
    "    x=-0.2,\n",
    "    y=-0.4,\n",
    "    showarrow=False,\n",
    "    align=\"left\",\n",
    "    font=dict(size=12)\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
